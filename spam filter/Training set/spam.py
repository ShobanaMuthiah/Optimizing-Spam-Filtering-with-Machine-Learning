# -*- coding: utf-8 -*-
"""spam.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DWJLTYpiRbBFjY2eL0bXJ2s4R8lqntxd

##IMPORTING LIBRARIES
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter  import PorterStemmer

"""##LODING DATASET"""

df = pd.read_csv("/content/spam.csv",encoding="latin")

df.head()

"""##GIVE CONCISE SUMMARY OF A DATASET"""

df.info()

"""##RETURN THE SUM OF ALL THE NULL VALUES"""

df.isna().sum()

"""##RENAMING THE COLUMNS"""

df.rename({"v1":"label","v2":"text"},inplace=True, axis=1)

"""##BOTTOM 5 ROWS OF THE DATAFRAME"""

df.tail()

"""##HANDLING CATEGORICAL VALUES"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['label']=le.fit_transform(df['label'])

"""##HANDLING IMBALANCE DATA"""

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

"""VECTORIZATION """

tf=TfidfVectorizer()
X=tf.fit_transform(df['text'])
import numpy as np
X=X.toarray()
X

"""DATA SPLITING INTO TRAIN AND VALIDATION SETS"""

X_train, X_test, y_train, y_test=train_test_split(X, df['label'], test_size=0.2, random_state=0)

#PIP INSTALL IMBLEARN
!pip install imbalanced_learn

print("Before OverSampling, counts of label '1': {}".format(sum(y_train==1)))
print("Before OverSampling, counts of label '0': {}\n".format(sum(y_train==0)))



from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=2)
X_train_res, y_train_res =sm.fit_resample(X_train, y_train.ravel())

print('After OverSampling,the shape of train_X: {}'.format(X_train_res.shape))
print('After OverSampling,the shape of train_y: {}\n'.format(y_train_res.shape))

print("After OverSampling, counts of label '1': {}".format(sum(y_train_res==1)))
print("After OverSampling, counts of label '0': {}\n".format(sum(y_train_res==0)))

"""##CLEANING THE DATASET"""

#DOWNLOADING STOPWORDS
nltk.download('stopwords')

import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer

import re
corpus=[]
length=len(df)

!pip install re

import re

for i in range(0,length):
  
  text=re.sub("[^a-z^A-Z^0-9]", " ",df['text'][i])
  text=text.lower()
  text=text.split()
  pe=PorterStemmer()
  stopword=stopwords.words("english")
  text=[pe.stem(word) for word in text if not word in set(stopword)]
  text=" ".join(text)
  corpus.append(text)

"""##TEXT PREPROCESSING"""

corpus

from sklearn.feature_extraction.text import CountVectorizer

cv=CountVectorizer(max_features=35000)
X=cv.fit_transform(corpus).toarray()

"""##SAVING INTO cv.pkl FILE"""

import pickle
pickle.dump(cv,open('cv1.pkl','wb'))

"""##EMPLORATORY DATA ANALYSIS"""

df.describe()

df.shape

"""##VISUAL ANALYSIS"""

#COUNT PLOT FUNCTION
df["label"].value_counts().plot(kind="bar",figsize=(12,6))
plt.xticks(np.arange(2),('Non Spam','spam'),rotation=0)

"""##SCALING THE DATA"""

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import scale

sc=StandardScaler()
x_bal=sc.fit_transform(X_train)

x_bal=pd.DataFrame(x_bal)

"""#MODEL BUILDING

##DECISION TREE MODEL
"""

from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

model=tree.DecisionTreeClassifier()
model.fit(X_train_res,y_train_res)

"""##RANDOM FOREST MODEL"""

from sklearn.ensemble import RandomForestClassifier
from sklearn import ensemble

model1=ensemble.RandomForestClassifier()
model1.fit(X_train_res,y_train_res)

"""##NAIVE BAYES MODEL"""

from sklearn.naive_bayes import MultinomialNB
from sklearn import naive_bayes
model=naive_bayes.MultinomialNB()
model.fit(X_train_res,y_train_res)

"""##ARTIFICIAL NEURAL NETWORK(ANN)"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model=Sequential()
X_train.shape

model.add(Dense(units=X_train_res.shape[1],activation="relu",kernel_initializer="random_uniform"))
model.add(Dense(units=100,activation="relu",kernel_initializer="random_uniform"))

model.add(Dense(units=1,activation="sigmoid"))
model.compile(optimizer="adam",loss="binary_crossentropy",metrics=['accuracy'])
generator=model.fit(X_train_res, y_train_res, epochs=10,steps_per_epoch=len(X_train_res)//64)

"""##TESTING THE MODEL"""

y_pred=model.predict(X_test)
y_pred=y_pred.flatten()

y_pr=np.where(y_pred>0.5,1,0)
y_pr

"""##SAVE THE MODEL INTO TEST THE INPUTS"""

filename="spam.h5"
model.save(filename)

from tensorflow.keras.models import load_model

loaded_model=load_model(str(filename))

import re

def new_review(new_review):

  new_review=new_review
  new_review=re.sub('[^a-zA-Z]',' ',str(new_review))

  new_review=new_review.lower()

  new_review.split()

  ps=PorterStemmer()
  all_stopwords=stopwords.words('english')
  all_stopwords.remove('not')
  new_review=[ps.stem(word) for word in new_review if not word in set(all_stopwords)] 

  new_review=' '.join(new_review)
  new_corpus=[new_review]
  new_X_test=cv.transform(new_corpus).toarray()
  print(new_X_test)

  from keras.models import loaded_model
  new_y_pred=loaded_model.predict(new_X_test)
  print(new_y_pred)
  new_X_pred=np.where(new_y_pred>0.5,1,0)
  return new_y_pred
  new_review=new_review(str(input("Enter new review...")))

"""#PERFORMANCE TESTING & HYPERPARAMETER TUNING

COMPARE THE MODEL (NAIVE BAYES)
"""

from sklearn.naive_bayes import MultinomialNB
import math
nb=MultinomialNB()
nb.fit(X_train_res,y_train_res)
y_pred=nb.predict(X_test)

from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score

print(confusion_matrix(y_test,y_pred))
score=(accuracy_score(y_test,y_pred))
print(score)
cm=score*100
print('Accuracy of NAVIE BAYES: ',cm )

"""COMPARE THE MODEL (DECISION TREE MODEL)"""

from sklearn.tree import DecisionTreeClassifier
nb1=DecisionTreeClassifier()
nb1.fit(X_train_res,y_train_res)
y_pred=nb1.predict(X_test)

print(confusion_matrix(y_test,y_pred))
SC=(accuracy_score(y_test,y_pred))
print(SC)
c=SC*100
print(c)

"""COMPARE THE MODEL(RANDOM FOREST MODEL"""

from sklearn.ensemble import RandomForestClassifier
from sklearn import ensemble

model1=ensemble.RandomForestClassifier()
model1.fit(X_train_res,y_train_res)


y_pred=model1.predict(X_test)

print(confusion_matrix(y_test,y_pred))
sc=(accuracy_score(y_test,y_pred))
print(sc)
m=sc*100
print(m)

"""#SAVING OUR MODEL"""

model.save('spam.h5')